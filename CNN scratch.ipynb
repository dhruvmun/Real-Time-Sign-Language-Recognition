{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/importlib/_bootstrap.py:321: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('sign_mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27455, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     13     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0     153    ...          207       207       207       207       206   \n",
       "1     158    ...           69       149       128        87        94   \n",
       "2     187    ...          202       201       200       199       198   \n",
       "3     210    ...          235       234       233       231       230   \n",
       "4     185    ...           92       105       105       108       133   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       206       204       203       202  \n",
       "1       163       175       103       135       149  \n",
       "2       199       198       195       194       195  \n",
       "3       226       225       222       229       163  \n",
       "4       163       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 28, 28, 1)\n",
      "(27455,)\n"
     ]
    }
   ],
   "source": [
    "pixels = dataset.ix[:,1:].values.astype('float32')\n",
    "label = dataset.ix[:,0].values.astype('int32')\n",
    "\n",
    "#Normalization\n",
    "pixels /= 255\n",
    "\n",
    "pixels = pixels.reshape(pixels.shape[0], 28, 28, 1)\n",
    "\n",
    "print (pixels.shape)\n",
    "print (label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2alph = {0:'a',1:'b',2:'c',3:'d',4:'e',5:'f',6:'g',7:'h',8:'i',9:'j',10:'k',11:'l',12:'m',13:'n',14:'o',\n",
    "            15:'p',16:'q',17:'r',18:'s',19:'t',20:'u',21:'v',22:'w',23:'x',24:'y',25:'z'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a=7\n",
    "plt.subplot(330 + a)\n",
    "plt.imshow(pixels[a], cmap=plt.get_cmap('gray'))\n",
    "plt.title(idx2alph[label[a]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 26)\n"
     ]
    }
   ],
   "source": [
    "# one-hot vector\n",
    "from keras.utils.np_utils import to_categorical\n",
    "label = to_categorical(label, 26)\n",
    "print (label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant', constant_values=0) \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (4, 3, 3, 2)\n",
      "x_pad.shape = (4, 7, 7, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6a0b4ffe48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 2)\n",
    "print (\"x.shape =\", x.shape)\n",
    "print (\"x_pad.shape =\", x_pad.shape)\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0,:,:,0])\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    s = np.multiply(a_slice_prev, W) + b\n",
    "    Z = np.sum(s)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    \n",
    "    n_H = int((n_H_prev - f + 2 * pad) / stride) + 1\n",
    "    n_W = int((n_W_prev - f + 2 * pad) / stride) + 1\n",
    "    \n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):                                 # loop over the batch of training examples\n",
    "        a_prev_pad = A_prev_pad[i]                     # Select ith training example's padded activation\n",
    "        for h in range(n_H):                           # loop over vertical axis of the output volume\n",
    "            for w in range(n_W):                       # loop over horizontal axis of the output volume\n",
    "                for c in range(n_C):                   # loop over channels (= #filters) of the output volume\n",
    "                    # Find the corners of the current \"slice\" (â‰ˆ4 lines)\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[...,c], b[...,c])\n",
    "    \n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean = 3.9125516483785905\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e7aaf6dbb443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Z's mean =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cache_conv[0][1][2][3] =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_conv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(1, 5, 5, 1)\n",
    "W = np.random.randn(2, 3, 3, 1)\n",
    "b = np.random.randn(1, 1, 1, 8)\n",
    "hparameters = {\"pad\" : 2,\n",
    "               \"stride\": 1}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "print(\"Z's mean =\", np.mean(Z))\n",
    "print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "image_size = 28\n",
    "num_channels = 1\n",
    "filter_size = 3\n",
    "depth = 4\n",
    "hidden1 = 256\n",
    "learning_rate = 0.1\n",
    "beta = 0\n",
    "\n",
    "num_classes = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid\n",
    "def sigmoid(X):\n",
    "    return 1/(1+np.exp(-1*X))\n",
    "\n",
    "#softmax\n",
    "def softmax(X):\n",
    "    exp_X = np.exp(X)\n",
    "    sum_exp_X = np.sum(exp_X,1).reshape(-1,1)  #col-wise sum\n",
    "    exp_X = exp_X/sum_exp_X\n",
    "    return exp_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Weights\n",
    "\n",
    "    conv_layer1_weights = [3,3,1,4]\n",
    "    conv_layer2_weights = [3,3,4,16]\n",
    "    full_layer1_weights = [504,256]\n",
    "    full_layer2_weights = [256,10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " def initialize_parameters():\n",
    "    #initialize weights values with 0 mean and 0.5 standard deviation.\n",
    "    mean = 0\n",
    "    std = 0.5\n",
    "    \n",
    "    #conv layer weights\n",
    "    conv_layer1_weights = np.random.normal(mean,std,(filter_size,filter_size,num_channels,depth))\n",
    "    conv_layer1_biases = np.zeros([1,depth])\n",
    "    conv_layer2_weights = np.random.normal(mean,std,(filter_size,filter_size,depth,depth*4))\n",
    "    conv_layer2_biases = np.zeros([1,depth*4])\n",
    "    \n",
    "    #fully-connected weights\n",
    "    full_layer1_weights = np.random.normal(mean,std,(((image_size//4-1) * (image_size//4-1) * depth * 4),hidden1))\n",
    "    full_layer1_biases = np.zeros([hidden1])\n",
    "    full_layer2_weights = np.random.normal(mean,std,(hidden1,num_classes))\n",
    "    full_layer2_biases = np.zeros([num_classes])\n",
    "    \n",
    "    parameters = dict()\n",
    "    parameters['cw1'] = conv_layer1_weights\n",
    "    parameters['cb1'] = conv_layer1_biases\n",
    "    parameters['cw2'] = conv_layer2_weights\n",
    "    parameters['cb2'] = conv_layer2_biases\n",
    "    parameters['fw1'] = full_layer1_weights\n",
    "    parameters['fb1'] = full_layer1_biases\n",
    "    parameters['fw2'] = full_layer2_weights\n",
    "    parameters['fb2'] = full_layer2_biases\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_multiply(image,weights):\n",
    "    hsize = (image.shape[0]-weights.shape[0])//2 + 1\n",
    "    vsize = (image.shape[1]-weights.shape[1])//2 + 1\n",
    "    logits = np.zeros([hsize,vsize,weights.shape[3]])\n",
    "    for d in range(weights.shape[3]):\n",
    "        row = 0\n",
    "        for rpos in range(0,(image.shape[0]-filter_size+1),2):\n",
    "            col=0\n",
    "            for cpos in range(0,(image.shape[1]-filter_size+1),2):\n",
    "                logits[row,col,d] = np.sum(np.multiply(image[rpos:rpos+filter_size, cpos:cpos+filter_size, :],weights[:,:,:,d]))\n",
    "                col += 1\n",
    "            row+=1\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORWARD PROPAGATION\n",
    "def forward_propagation(dataset,parameters):\n",
    "    #convolution layers activations\n",
    "    m = dataset.shape[0]\n",
    "    \n",
    "    #get the parameters\n",
    "    cw1 = parameters['cw1']\n",
    "    cb1 = parameters['cb1']\n",
    "    cw2 = parameters['cw2']\n",
    "    cb2 = parameters['cb2']\n",
    "    \n",
    "    fw1 = parameters['fw1']\n",
    "    fb1 = parameters['fb1']\n",
    "    fw2 = parameters['fw2']\n",
    "    fb2 = parameters['fb2']\n",
    "    \n",
    "    #to store the intermediate activations for backward propagation\n",
    "    cache = dict()\n",
    "    \n",
    "    conv_activation1 = list()\n",
    "    conv_activation2 = list()\n",
    "    \n",
    "    #image by image convolutional forward propagation\n",
    "    for i in range(m):\n",
    "        image = dataset[i]\n",
    "        logits = conv_multiply(image,cw1) + cb1\n",
    "        ca1 = sigmoid(logits)\n",
    "        ca2 = sigmoid(conv_multiply(ca1,cw2) + cb2).reshape((image_size // 4 -1) * (image_size // 4 -1) * depth * 4)\n",
    "        \n",
    "        conv_activation1.append(ca1)\n",
    "        conv_activation2.append(ca2)\n",
    "        \n",
    "    #convert into numpy array\n",
    "    conv_activation1 = np.array(conv_activation1).reshape(m,image_size // 2 -1, image_size // 2 -1, depth)\n",
    "    conv_activation2 = np.array(conv_activation2).reshape(m,image_size // 4 -1, image_size // 4 -1, depth * 4)\n",
    "        \n",
    "    #expand the conv_activation2 into (m,num_features) \n",
    "    #num_features = (image_size // 4 * image_size // 4 * depth * 4)\n",
    "    temp_activation = np.array(conv_activation2).reshape(m,(image_size // 4 -1) * (image_size // 4-1) * depth * 4)\n",
    "    \n",
    "    #fully connected layers activations\n",
    "    full_activation1 = np.matmul(temp_activation,fw1) + fb1\n",
    "    full_activation1 = sigmoid(full_activation1)\n",
    "    full_activation2 = np.matmul(full_activation1,fw2) + fb2\n",
    "    output = softmax(full_activation2)\n",
    "    \n",
    "    cache['ca1'] = conv_activation1\n",
    "    cache['ca2'] = conv_activation2\n",
    "    cache['fa1'] = full_activation1\n",
    "    cache['output'] = output\n",
    "    return cache,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate conv deltas or errors only for one example\n",
    "def conv_delta(next_error,weights):\n",
    "    delta = np.zeros([next_error.shape[0]*2+1,next_error.shape[1]*2+1,next_error.shape[2]//4])\n",
    "    for d in range(weights.shape[3]):\n",
    "        row = 0\n",
    "        for rpos in range(0,delta.shape[0]-filter_size+1,2):\n",
    "            col=0\n",
    "            for cpos in range(0,delta.shape[2]-filter_size+1,2):\n",
    "                delta[rpos:rpos+filter_size,cpos:cpos+filter_size,:] += weights[:,:,:,d]*next_error[row,col,d]\n",
    "                col+=1\n",
    "            row +=1\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv partial derivatives only for single example\n",
    "def conv_derivatives(delta,activation):\n",
    "    partial_derivatives = np.zeros([filter_size,filter_size,activation.shape[2],delta.shape[2]])\n",
    "    for d2 in range(0,partial_derivatives.shape[3]):\n",
    "        row=0\n",
    "        for rpos in range(0,activation.shape[0]-filter_size+1,2):\n",
    "            col = 0\n",
    "            for cpos in range(0,activation.shape[1]-filter_size+1,2):\n",
    "                partial_derivatives[:,:,:,d2] += np.multiply(activation[rpos:rpos+filter_size, cpos:cpos+filter_size, :],delta[row,col,d2])\n",
    "                col += 1\n",
    "            row += 1\n",
    "    return partial_derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(dataset,labels,cache,parameters):\n",
    "    #get activations\n",
    "    output = cache['output']\n",
    "    fa1 = cache['fa1']\n",
    "    ca2 = cache['ca2']\n",
    "    ca1 = cache['ca1']\n",
    "    \n",
    "    temp_act = np.array(ca2).reshape(-1,(image_size // 4-1) * (image_size // 4 -1)* depth * 4)\n",
    "    \n",
    "    #get parameters\n",
    "    cw1 = parameters['cw1']\n",
    "    cw2 = parameters['cw2']\n",
    "    fw1 = parameters['fw1']\n",
    "    fw2 = parameters['fw2']\n",
    "    \n",
    "    \n",
    "    #cal errors fully connected\n",
    "    error_fa2 = output - labels\n",
    "    error_fa1 = np.matmul(error_fa2,fw2.T)\n",
    "    error_fa1 = np.multiply(error_fa1,fa1)\n",
    "    error_fa1 = np.multiply(error_fa1,(1-fa1))\n",
    "    error_temp = np.matmul(error_fa1,fw1.T)\n",
    "    error_temp = np.multiply(error_temp,temp_act)\n",
    "    error_temp = np.multiply(error_temp,(1-temp_act))\n",
    "    \n",
    "    m = dataset.shape[0]\n",
    "    \n",
    "    #cal errors conv layers\n",
    "    error_ca2 = np.array(error_temp).reshape(-1,image_size//4-1,image_size//4-1,depth*4)\n",
    "    error_ca1 = np.zeros(ca1.shape)\n",
    "    ## Image by Image error\n",
    "    for i in range(m):\n",
    "        error = conv_delta(error_ca2[i],cw2)\n",
    "        error = np.multiply(error,ca1[i])\n",
    "        error = np.multiply(error,(1-ca1[i]))\n",
    "        error_ca1 += error\n",
    "    \n",
    "    \n",
    "    #calculate partial derivatives\n",
    "    #fully connected layers\n",
    "    fd2 = (np.matmul(fa1.T,error_fa2) + beta*fw2)/m\n",
    "    fd1 = (np.matmul(temp_act.T,error_fa1) + beta*fw1)/m\n",
    "    \n",
    "    #conv layers\n",
    "    cd2 = np.zeros(cw2.shape)\n",
    "    cd1 = np.zeros(cw1.shape)\n",
    "    \n",
    "    ##Image by Image derivatives\n",
    "    for i in range(m):\n",
    "        cd2 = cd2 + conv_derivatives(error_ca2[i],ca1[i])\n",
    "        cd1 = cd1 + conv_derivatives(error_ca1[i],dataset[i])\n",
    "    cd2 = (cd2 + beta*cw2)/m\n",
    "    cd1 = (cd1 + beta*cw1)/m\n",
    "    \n",
    "    \n",
    "    #store the derivatives in dict\n",
    "    derivatives = dict()\n",
    "    \n",
    "    derivatives['cd1'] = cd1\n",
    "    derivatives['cd2'] = cd2\n",
    "    derivatives['fd1'] = fd1\n",
    "    derivatives['fd2'] = fd2\n",
    "    \n",
    "    return derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(derivatives,parameters):\n",
    "    #get parameters\n",
    "    cw1 = parameters['cw1']\n",
    "    cw2 = parameters['cw2']\n",
    "    fw1 = parameters['fw1']\n",
    "    fw2 = parameters['fw2']\n",
    "    \n",
    "    #get derivatives\n",
    "    cd1 = derivatives['cd1']\n",
    "    cd2 = derivatives['cd2']\n",
    "    fd1 = derivatives['fd1']\n",
    "    fd2 = derivatives['fd2']\n",
    "    \n",
    "    #update\n",
    "    cw1 = cw1 - learning_rate*cd1\n",
    "    cw2 = cw2 - learning_rate*cd2\n",
    "    fw1 = fw1 - learning_rate*fd1\n",
    "    fw2 = fw2 - learning_rate*fd2\n",
    "    \n",
    "    #update the dict\n",
    "    parameters['cw1'] = cw1\n",
    "    parameters['cw2'] = cw2\n",
    "    parameters['fw1'] = fw1\n",
    "    parameters['fw2'] = fw2\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss_accuracy(true_labels,predictions,parameters):\n",
    "    #get parameters\n",
    "    cw1 = parameters['cw1']\n",
    "    cw2 = parameters['cw2']\n",
    "    fw1 = parameters['fw1']\n",
    "    fw2 = parameters['fw2']\n",
    "    \n",
    "    m = len(true_labels)\n",
    "    \n",
    "    #cal loss\n",
    "    loss = -1*(np.sum(np.multiply(np.log(predictions),true_labels),1) + np.sum(np.multiply(np.log(1-predictions),1-true_labels),1))\n",
    "    loss = np.sum(loss)\n",
    "    loss = loss + beta*(np.sum(cw1**2) + np.sum(cw2**2) + np.sum(fw1**2) + np.sum(fw2**2))\n",
    "    loss = loss/m\n",
    "    \n",
    "    #cal accuracy\n",
    "    accuracy = np.sum(np.argmax(true_labels,1)==np.argmax(predictions,1))/m\n",
    "    \n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def train(train_dataset,train_labels,batch_size=20,iters=101,stride=2):\n",
    "    \n",
    "    #print(train_dataset.shape)\n",
    "    #initialize the parameters\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    cw1 = parameters['cw1']\n",
    "    cb1 = parameters['cb1']\n",
    "    cw2 = parameters['cw2']\n",
    "    cb2 = parameters['cb2']\n",
    "    \n",
    "    fw1 = parameters['fw1']\n",
    "    fb1 = parameters['fb1']\n",
    "    fw2 = parameters['fw2']\n",
    "    fb2 = parameters['fb2']\n",
    "    \n",
    "    J = []  #store the loss o every batch\n",
    "    A = []  #store the accuracy of every batch\n",
    "    \n",
    "    \n",
    "    #training process.\n",
    "    for step in range(iters):\n",
    "        #get the batch data.\n",
    "        start = (step*batch_size)%(train_dataset.shape[0])\n",
    "        end = start + batch_size\n",
    "        \n",
    "        batch_dataset = train_dataset[start:end, : , : , : ]\n",
    "        batch_labels = train_labels[start:end, : ]\n",
    "        \n",
    "        #forward propagation\n",
    "        cache,output = forward_propagation(batch_dataset,parameters)\n",
    "        \n",
    "        #cal_loss and accuracy\n",
    "        loss,accuracy = cal_loss_accuracy(batch_labels,output,parameters)\n",
    "        \n",
    "        #calculate the derivatives\n",
    "        derivatives = backward_propagation(batch_dataset,batch_labels,cache,parameters)\n",
    "        \n",
    "        #update the parameters\n",
    "        parameters = update_parameters(derivatives,parameters)\n",
    "        \n",
    "        #append the loss and accuracy of every batch\n",
    "        J.append(loss)\n",
    "        A.append(accuracy)\n",
    "        \n",
    "        #print loss and accuracy of the batch dataset.\n",
    "        if(step%100==0):\n",
    "            print('Step : %d'%step)\n",
    "            print('Loss : %f'%loss)\n",
    "            print('Accuracy : %f%%'%(round(accuracy*100,2)))\n",
    "            \n",
    "    return J,A,parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 28, 28, 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-6a20bfe2a86d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#TRAINING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-91a547bd417d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataset, train_labels, batch_size, iters, stride)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mbatch_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "J,A,parameters = train(pixels,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
